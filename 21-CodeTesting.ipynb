{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clicker Warm Up\n",
    "\n",
    "Create a class called `Football` with two instance attributes: `team` and `location`. \n",
    "\n",
    "Within `Football`, include a method (`speak_truths`) that returns 'The Patriots lost to the Ravens!' if `team` is 'Patriots' or `location` is 'New England' and 'Nobody likes the Patriots.' otherwise.\n",
    "\n",
    "- A) I did it!\n",
    "- B) I think I did it!\n",
    "- C) I'm stuck.\n",
    "\n",
    "Frequency Code: CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Football():\n",
    "    \n",
    "    def __init__(self, team = None, location = None):\n",
    "        self.team = team\n",
    "        self.location = location\n",
    "    \n",
    "    def speak_truths(self):\n",
    "        if self.team == 'Patriots' or self.location == 'New England':\n",
    "            return 'The Patriots lost to the Ravens!'\n",
    "        else:\n",
    "            return 'Nobody likes the Patriots.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nobody likes the Patriots.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Football(team='patriots').speak_truths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code Testing\n",
    "\n",
    "- smoke tests\n",
    "- unit tests\n",
    "- `pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clicker Question #1\n",
    "\n",
    "Given the following code, which assert will fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def extend(input_arg):\n",
    "    output = input_arg.copy()\n",
    "    for element in input_arg:\n",
    "        output.append(element)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extend([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A) `assert isinstance(extend([1, 2]), list)`\n",
    "- B) `assert extend([1, 2]) == [1, 2, 1, 2]`\n",
    "- C) `assert extend((1, 2)) == (1, 2, 1, 2)` \n",
    "- D) `assert extend(['a', 'b', 'c']) == ['a', 'b', 'c', 'a', 'b', 'c']`\n",
    "- E) `assert extend([]) == []`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clicker Question - Asserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Check that extend returns a list\n",
    "assert isinstance(extend([1, 2]), list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Check that an input list returns the expected result\n",
    "assert extend([1, 2]) == [1, 2, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c510c0c20682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check if the function works on tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-a3ca5f93bd43>\u001b[0m in \u001b[0;36mextend\u001b[0;34m(input_arg)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "# Check if the function works on tuples\n",
    "assert extend((1, 2)) == (1, 2, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Check that a different input list (different lengths / contents) returns expected result\n",
    "assert extend(['a', 'b', 'c']) == ['a', 'b', 'c', 'a', 'b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Check that an empty list executes, executing an empty list\n",
    "assert extend([]) == []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Code Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Code tests is code that runs and checks other code, to make sure it does what it is expected to do. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to Write Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Given a function or class you want to test:\n",
    "- You need to have an expectation for what it should do\n",
    "- Write out some example cases, with known answers\n",
    "- Use `assert` to check that your example cases do run as expected\n",
    "- Collect these examples into test functions, stored in test files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Write Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To ensure code does what it is supposed to\n",
    "- To have a system for checking things when you change things in the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Best (Laziest) Argument for Writing Tests\n",
    "\n",
    "Whenever you write new code, you will find yourself using little snippets of code to check it. \n",
    "\n",
    "Collect these snippets into a test function, and you get re-runnable tests for free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def add(num1, num2):\n",
    "    return num1 + num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9000000000000004"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(2.7, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def test_add():\n",
    "    \"\"\"Tests for the `add` function.\"\"\"\n",
    "    \n",
    "    # Test adding positve numbers\n",
    "    assert add(2, 2) == 4\n",
    "    \n",
    "    # Test adding negative numbers\n",
    "    assert add(-2, -2) == -4\n",
    "    \n",
    "    # Test adding floats\n",
    "    # assert add(2.7, 1.2) == 3.9\n",
    "    assert math.isclose(add(2.7, 1.2), 3.9)\n",
    "    \n",
    "    # Test adding with 0\n",
    "    assert add(2, 0) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Run our test function\n",
    "test_add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clicker Question #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Given the following function:\n",
    "def divide_list(in_list):    \n",
    "    output = []\n",
    "    \n",
    "    for el1, el2 in zip(in_list[1:], in_list[0:-1]):\n",
    "        output.append(el1 / el2)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# And the following test function:\n",
    "def test_divide_list():\n",
    "    assert isinstance(divide_list([1, 2]), list)\n",
    "    assert divide_list([1, 2, 4]) == [2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_divide_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A) These tests will pass, and this function is well tested\n",
    "- B) These tests will pass, but this function needs more tests\n",
    "- C) These tests will fail, but they cover the needed cases\n",
    "- D) These tests will fail, and we should also have more tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PyTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b><a href = 'https://docs.pytest.org/en/latest/'> PyTest </a></b> is a module that for writing and running test code. It is available from Anaconda and datahub.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Levels of Code Testing:\n",
    "\n",
    "- Smoke Tests\n",
    "- **Unit Tests**\n",
    "- Integration Tests\n",
    "- System Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test Driven Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "In software development, <b>test-driven development</b> is an approach in which you write tests first -  and then write code to pass the tests. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test Driven Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Ensures you go into writing code with a good plan / outline\n",
    "- Ensures that you have a test suite, as you can not decide to neglect test code after the fact\n",
    "- Note: when you complete (or at least write) assignments for this class, you are effectively doing test-driven development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Test coverage</b> is the proportion of a software project that is run by the test suite. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Writing Good Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "All in all, write code that is:\n",
    "- Documented\n",
    "- Well organized (follows a style guide)\n",
    "- Tested\n",
    "\n",
    "And you will have understandable, maintainable, and trustable code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Why We Write Tests:\n",
    "\n",
    "- ensure does does what it's supposed to\n",
    "- system for checking things when you change / make updates in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Tests, when run, help identify code that will give if something has gone wrong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Four general types\n",
    "\n",
    "1. **Smoke tests** - preliminary tests to basic functionality; checks if something runs (but not necessarily if it does the right thing) (sanity check) \n",
    "2. **Unit tests** - test functions & objects to ensure that they code is behaving as expected\n",
    "3. **Integration tests** - tests functions, classes & modules interacting\n",
    "4. **System tests** - tests end-to-end behavior "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Not tests, but related\n",
    "- asserts - make a statement of fact about code \n",
    "- static checks - check your code as you go that it behaves as expected\n",
    "- argument validation - checks to see if the input given to a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unit Tests\n",
    "\n",
    "- one test for each \"piece\" of your code (each function, each class, each module, etc)\n",
    "- passes silently if true\n",
    "- error if it fails\n",
    "- consider \"edge cases\"\n",
    "- help you resist the urge to assume computers will act how you think it will work \n",
    "- functions used with pytest start with `test_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `pytest`\n",
    "\n",
    "- check if error raised when expected to be raised\n",
    "- autorun all of your tests\n",
    "- formal testing to your code/projects\n",
    "\n",
    "#### Executing `pytest`\n",
    "\n",
    "1. Look for any file called `test_...`\n",
    "2. If everything works, silently moves along. \n",
    "4. For anything that fails, will alert you.\n",
    "\n",
    "**Available from Anaconda and on datahub**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clicker Question #3\n",
    "\n",
    "Write a test function that checks the following piece of code:\n",
    "\n",
    "- A) I did it!\n",
    "- B) I think I did it!\n",
    "- C) I'm lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought process:\n",
    "1. Define test function `def test_...`\n",
    "2. make `assert`ion within the test function\n",
    "    - check that function sums the list (which was our expectation)\n",
    "    - check that the input was a list (either in function or test function)\n",
    "    - check the output is expected output / expected type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_list(input_list):\n",
    "    \"\"\"add all values in a list - return sum\"\"\"\n",
    "    \n",
    "    output = 0\n",
    "    \n",
    "    for val in input_list:\n",
    "        output += val\n",
    "        \n",
    "    return output\n",
    "\n",
    "sum_list([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR TEST\n",
    "def test_sum_list():\n",
    "    assert sum_list([1, 2, 3, 4]) == 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sum_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "### POSSIBLE TEST\n",
    "def test_sum_list():\n",
    "    \n",
    "    # write multiple asserts\n",
    "    assert callable(sum_list)\n",
    "    assert isinstance(sum_list([1, 2, 3, 4]), int)\n",
    "    assert sum_list([1, 2, 3, 4]) == 10\n",
    "    \n",
    "test_sum_list()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
